[Machine Learning A-Zâ„¢: Hands-On Python & R In Data Science](https://www.udemy.com/machinelearning/)

* Materials
* My Notes [Jupyter Notebook]
* [Important links](#importantLinks)

* * *

* **Part 1 - Data Preprocessing**

	* [[Python] Data Preprocessing](http://nbviewer.jupyter.org/github/Dibakarroy1997/machinelearning/blob/master/Part%201%20-%20Data%20Preprocessing/%5BPython%5D%20Data%20Preprocessing.ipynb)
	* [[R] Data Preprocessing](http://nbviewer.jupyter.org/github/Dibakarroy1997/machinelearning/blob/master/Part%201%20-%20Data%20Preprocessing/%5BR%5D%20Data%20Preprocessing.ipynb)

	* **Steps involved**: *Import the dataset -> Taking care of missing data -> Encoding categorical data -> Splitting the dataset into Trainingset and Test set -> Feature Scaling*

* * *

* **Part 2 - Regression**
	* **Simple Linear Regression** 
		* [[Python] Simple Linear Regression](http://nbviewer.jupyter.org/github/Dibakarroy1997/machinelearning/blob/master/Part%202%20-%20Regression/Simple%20Linear%20Regression/%5BPython%5D%20Simple%20Linear%20Regression.ipynb)
		* [[R] Simple Linear Regression](http://nbviewer.jupyter.org/github/Dibakarroy1997/machinelearning/blob/master/Part%202%20-%20Regression/Simple%20Linear%20Regression/%5BR%5D%20Simple%20Linear%20Regression.ipynb)

		* **Steps involved**: *Data preprocessing -> Fitting Simple Linear Regression to the Training Set -> Predicting the Test set result -> Visualising the Training set results -> Visualising the Test set results*

	* **Multiple Linear Regression**
		* [[Python] Multiple Linear Regression](http://nbviewer.jupyter.org/github/Dibakarroy1997/machinelearning/blob/master/Part%202%20-%20Regression/Multiple%20Linear%20Regression/%5BPython%5D%20Multiple%20Linear%20Regression.ipynb)
		* [[R] Multiple Linear Regression](http://nbviewer.jupyter.org/github/Dibakarroy1997/machinelearning/blob/master/Part%202%20-%20Regression/Multiple%20Linear%20Regression/%5BR%5D%20Multiple%20Linear%20Regression.ipynb)

		* **Steps involved**: *Data prepocessing [Encoding categorical data(if any) -> Avoid dummy variable trap(can be done using Python and R library)] -> Fitting Multiple Linear Regression to the training set -> Predicting the test set reults*

		* [**For steps needed for Backward Elimination please refer to the pdf**](https://github.com/Dibakarroy1997/machinelearning/blob/master/Part%202%20-%20Regression/Multiple%20Linear%20Regression/Step-by-step-Blueprints-For-Building-Models.pdf)

	* **Polynomial Regression**
		* [[Python] Polynomial Regression](http://nbviewer.jupyter.org/github/Dibakarroy1997/machinelearning/blob/master/Part%202%20-%20Regression/Polynomial%20Regression/%5BPython%5D%20Polynomial%20Regression.ipynb)
		* [[R] Polynomial Regression](http://nbviewer.jupyter.org/github/Dibakarroy1997/machinelearning/blob/master/Part%202%20-%20Regression/Polynomial%20Regression/%5BR%5D%20Polynomial%20Regression.ipynb)

		* **Steps involved**: *Data preprocessing -> Fitting Polynomial Regression to the dataset -> Visualising the Polynomial Regression results -> Adjust degree -> Get a more continuous curve -> Predicting a new result with Polynomial Regression*

	* **Support Vector Regression**
		* [[Python] Support Vector Regression (SVR)](http://nbviewer.jupyter.org/github/Dibakarroy1997/machinelearning/blob/master/Part%202%20-%20Regression/Support%20Vector%20Regression%20%28SVR%29/%5BPython%5D%20Support%20Vector%20Regression%20%28SVR%29.ipynb)
		* [[R] Support Vector Regression (SVR)](http://nbviewer.jupyter.org/github/Dibakarroy1997/machinelearning/blob/master/Part%202%20-%20Regression/Support%20Vector%20Regression%20%28SVR%29/%5BR%5D%20Support%20Vector%20Regression%20%28SVR%29.ipynb)

		* **Steps involved**: *Data preprocessing (for python we need to do Feature Scaling) -> Fitting the SVR Model to the dataset-> Predicting a new result -> Visualising the SVR Regression results*

	* **Decision Tree Regression**
		* [[Python] Decision Tree Regression](http://nbviewer.jupyter.org/github/Dibakarroy1997/machinelearning/blob/master/Part%202%20-%20Regression/Decision%20Tree%20Regression/%5BPython%5D%20Decision%20Tree%20Regression.ipynb)
		* [[R] Decision Tree Regression](http://nbviewer.jupyter.org/github/Dibakarroy1997/machinelearning/blob/master/Part%202%20-%20Regression/Decision%20Tree%20Regression/%5BR%5D%20Decision%20Tree%20Regression.ipynb)

		* **Steps involved**: *Data preprocessing -> Fitting the Decision Tree Regression Model to the dataset -> Predicting a new result -> Visualising the Decision Tree Regression results*

	* **Random Forest Regression**
		* [[Python] Random Forest Regression](http://nbviewer.jupyter.org/github/Dibakarroy1997/machinelearning/blob/master/Part%202%20-%20Regression/Random%20Forest%20Regression/%5BPython%5D%20Random%20Forest%20Regression.ipynb)
		* [[R] Random Forest Regression](http://nbviewer.jupyter.org/github/Dibakarroy1997/machinelearning/blob/master/Part%202%20-%20Regression/Random%20Forest%20Regression/%5BR%5D%20Random%20Forest%20Regression.ipynb)

		* **Steps involved**: *Data preprocessing -> Fitting the Random Forest Regression Model to the dataset (tweak the NTree parameter)-> Predicting a new result -> Visualising the Random Forest Regression results*

* * *

* **Part 3 - Classification**
	* **Logistic Regression** 
		* [[Python] Logistic Regression](http://nbviewer.jupyter.org/github/Dibakarroy1997/machinelearning/blob/master/Part%203%20-%20Classification/Logistic%20Regression/%5BPython%5D%20Logistic%20Regression.ipynb)
		* [[R] Logistic Regression](http://nbviewer.jupyter.org/github/Dibakarroy1997/machinelearning/blob/master/Part%203%20-%20Classification/Logistic%20Regression/%5BR%5D%20Logistic%20Regression.ipynb)

		* **Steps involved**: *Data preprocessing -> Fitting Logistic Regression to the Training Set -> Predicting the Test set result -> Making and analysing the Confusion Matrix -> Visualising the Training set results -> Visualising the Test set results*

	* **K-Nearest Neighbors** 
		* [[Python] K-Nearest Neighbors](http://nbviewer.jupyter.org/github/Dibakarroy1997/machinelearning/blob/master/Part%203%20-%20Classification/K%20Nearest%20Neighbors/%5BPython%5D%20K-Nearest%20Neighbour.ipynb)
		* [[R] K-Nearest Neighbors](http://nbviewer.jupyter.org/github/Dibakarroy1997/machinelearning/blob/master/Part%203%20-%20Classification/K%20Nearest%20Neighbors/%5BR%5D%20K-Nearest%20Neighbour.ipynb)

		* **Steps involved**: *Data preprocessing -> Fitting K-Nearest Neighbor Classifier to the Training Set -> Predicting the Test set result -> Making and analysing the Confusion Matrix -> Visualising the Training set results -> Visualising the Test set results*

	* **Support Vector Machine** 
		* [[Python] Support Vector Machine](http://nbviewer.jupyter.org/github/Dibakarroy1997/machinelearning/blob/master/Part%203%20-%20Classification/Support%20Vector%20Machine/%5BPython%5D%20Support%20Vector%20Machine.ipynb)
		* [[R] Support Vector Machine](http://nbviewer.jupyter.org/github/Dibakarroy1997/machinelearning/blob/master/Part%203%20-%20Classification/Support%20Vector%20Machine/%5BR%5D%20Support%20Vector%20Machine.ipynb)

		* **Steps involved**: *Data preprocessing -> Fitting Support Vector Machine Classifier to the Training Set -> Predicting the Test set result -> Making and analysing the Confusion Matrix -> Visualising the Training set results -> Visualising the Test set results*

	* **Kernel SVM** 
		* [[Python] Kernel SVM](http://nbviewer.jupyter.org/github/Dibakarroy1997/machinelearning/blob/master/Part%203%20-%20Classification/Kernel%20SVM/%5BPython%5D%20Kernel%20SVM.ipynb)
		* [[R] Kernel SVM](http://nbviewer.jupyter.org/github/Dibakarroy1997/machinelearning/blob/master/Part%203%20-%20Classification/Kernel%20SVM/%5BR%5D%20Kernel%20SVM.ipynb)

		* **Steps involved**: *Data preprocessing -> Fitting Kernel SVM to the Training Set -> Predicting the Test set result -> Making and analysing the Confusion Matrix -> Visualising the Training set results -> Visualising the Test set results*

	* **Naive Bayes** 
		* [[Python] Naive Bayes](http://nbviewer.jupyter.org/github/Dibakarroy1997/machinelearning/blob/master/Part%203%20-%20Classification/Naive%20Bayes/%5BPython%5D%20Naive%20Bayes.ipynb)
		* [[R] Naive Bayes](http://nbviewer.jupyter.org/github/Dibakarroy1997/machinelearning/blob/master/Part%203%20-%20Classification/Naive%20Bayes/%5BR%5D%20Naive%20Bayes.ipynb)

		* **Steps involved**: *Data preprocessing [Here Encoding the target feature as factor is compulsory in R] -> Fitting Naive Bayes to the Training Set -> Predicting the Test set result -> Making and analysing the Confusion Matrix -> Visualising the Training set results -> Visualising the Test set results*

* * *

<a name="importantLinks"></a>
**Important Links**

* [Installing anaconda](https://conda.io/docs/install/quick.html)
* [Installing Python and R using conda](https://uoftcoders.github.io/studyGroup/lessons/r-python-conda-setup/)
* [Using Jupyter notebook](https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/)

* * *