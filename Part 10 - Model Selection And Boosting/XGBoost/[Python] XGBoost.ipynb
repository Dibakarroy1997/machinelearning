{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TE-F73o_lVix"
   },
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tzzmmSI5lViy"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "dpwvxRAblViz"
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [14, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "lCtaPMJTlVi4"
   },
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 100,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1407,
     "status": "ok",
     "timestamp": 1514457086840,
     "user": {
      "displayName": "Debakar Roy",
      "photoUrl": "//lh5.googleusercontent.com/-KwEZ1Z4ZXmE/AAAAAAAAAAI/AAAAAAAAALg/j6T-KetMTHY/s50-c-k-no/photo.jpg",
      "userId": "103957503016432867835"
     },
     "user_tz": -330
    },
    "id": "5wawZXMUlVi7",
    "outputId": "76c5f795-8db3-40fd-fa7f-ba7eabdda385"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "\n",
       "   Tenure  Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
       "0       2      0.0              1          1               1        101348.88   \n",
       "\n",
       "   Exited  \n",
       "0       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "XP1Yf2_WlVjA"
   },
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, [3, 4, 6, 7, 8, 9, 10, 11, 12]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "jY1psvAilVjE"
   },
   "outputs": [],
   "source": [
    "y = dataset.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 700,
     "status": "ok",
     "timestamp": 1514457090725,
     "user": {
      "displayName": "Debakar Roy",
      "photoUrl": "//lh5.googleusercontent.com/-KwEZ1Z4ZXmE/AAAAAAAAAAI/AAAAAAAAALg/j6T-KetMTHY/s50-c-k-no/photo.jpg",
      "userId": "103957503016432867835"
     },
     "user_tz": -330
    },
    "id": "6at5ReinlVjI",
    "outputId": "4d77f6d2-fdf2-4e0b-c419-cf1bd1e9d1bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([619, 'France', 42, 2, 0.0, 1, 1, 1, 101348.88], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1091,
     "status": "ok",
     "timestamp": 1514457092170,
     "user": {
      "displayName": "Debakar Roy",
      "photoUrl": "//lh5.googleusercontent.com/-KwEZ1Z4ZXmE/AAAAAAAAAAI/AAAAAAAAALg/j6T-KetMTHY/s50-c-k-no/photo.jpg",
      "userId": "103957503016432867835"
     },
     "user_tz": -330
    },
    "id": "hBozvgKwlVjN",
    "outputId": "844e85b9-1689-4afc-8e2f-a96e38cd3b52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "I9Z85hGOlVjR"
   },
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X.fit_transform(X[:, 1])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 153,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 731,
     "status": "ok",
     "timestamp": 1514457094143,
     "user": {
      "displayName": "Debakar Roy",
      "photoUrl": "//lh5.googleusercontent.com/-KwEZ1Z4ZXmE/AAAAAAAAAAI/AAAAAAAAALg/j6T-KetMTHY/s50-c-k-no/photo.jpg",
      "userId": "103957503016432867835"
     },
     "user_tz": -330
    },
    "id": "20gQDph0lVjX",
    "outputId": "fe2826b1-f7dd-48fa-ec29-e8b4918be016"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   0.00000000e+00,   6.19000000e+02,\n",
       "          4.20000000e+01,   2.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.01348880e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   6.08000000e+02,\n",
       "          4.10000000e+01,   1.00000000e+00,   8.38078600e+04,\n",
       "          1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.12542580e+05]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "SvXnkj6dlVjg"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting XGBoost to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L12P_o4erF7u"
   },
   "source": [
    "### Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 187,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 930,
     "status": "ok",
     "timestamp": 1514457229492,
     "user": {
      "displayName": "Debakar Roy",
      "photoUrl": "//lh5.googleusercontent.com/-KwEZ1Z4ZXmE/AAAAAAAAAAI/AAAAAAAAALg/j6T-KetMTHY/s50-c-k-no/photo.jpg",
      "userId": "103957503016432867835"
     },
     "user_tz": -330
    },
    "id": "JlQeMV_KlVkR",
    "outputId": "45106a9a-e913-4b7c-ccfb-8ba072d4833d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1043,
     "status": "ok",
     "timestamp": 1514457230888,
     "user": {
      "displayName": "Debakar Roy",
      "photoUrl": "//lh5.googleusercontent.com/-KwEZ1Z4ZXmE/AAAAAAAAAAI/AAAAAAAAALg/j6T-KetMTHY/s50-c-k-no/photo.jpg",
      "userId": "103957503016432867835"
     },
     "user_tz": -330
    },
    "id": "QarCqejmlVkX",
    "outputId": "6dca82e2-d9ba-496d-8000-faad3a2fb484"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aZc829hFrJWC"
   },
   "source": [
    "### Making the confussion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 848,
     "status": "ok",
     "timestamp": 1514457232033,
     "user": {
      "displayName": "Debakar Roy",
      "photoUrl": "//lh5.googleusercontent.com/-KwEZ1Z4ZXmE/AAAAAAAAAAI/AAAAAAAAALg/j6T-KetMTHY/s50-c-k-no/photo.jpg",
      "userId": "103957503016432867835"
     },
     "user_tz": -330
    },
    "id": "1Da93HaSlVkd",
    "outputId": "c1a280e9-0eab-4e5b-a297-0c31c6411fc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1532,   63],\n",
       "       [ 203,  202]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4IQUImS6rMUL"
   },
   "source": [
    "### Calculating Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 983,
     "status": "ok",
     "timestamp": 1514457233329,
     "user": {
      "displayName": "Debakar Roy",
      "photoUrl": "//lh5.googleusercontent.com/-KwEZ1Z4ZXmE/AAAAAAAAAAI/AAAAAAAAALg/j6T-KetMTHY/s50-c-k-no/photo.jpg",
      "userId": "103957503016432867835"
     },
     "user_tz": -330
    },
    "id": "MrryNyCllVkg",
    "outputId": "55da9119-4526-433d-c224-85997c93a8ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86699999999999999"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cm[0][0]+cm[1][1])/np.sum(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying k-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.87640449,  0.8639201 ,  0.88125   ,  0.86625   ,  0.86375   ,\n",
       "        0.855     ,  0.865     ,  0.8575    ,  0.8485607 ,  0.87359199])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = cross_val_score(estimator = classifier, \n",
    "                             X = X_train,\n",
    "                             y = y_train,\n",
    "                             cv = 10)\n",
    "accuracies # 10 test set accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86512272851207572"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies) # mean of accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0094793902817781814"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(accuracies) # startdard deviation of accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Grid Search to find the best model and the best parameters (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on XGBClassifier in module xgboost.sklearn object:\n",
      "\n",
      "class XGBClassifier(XGBModel, sklearn.base.ClassifierMixin)\n",
      " |  Implementation of the scikit-learn API for XGBoost classification.\n",
      " |  \n",
      " |      Parameters\n",
      " |  ----------\n",
      " |  max_depth : int\n",
      " |      Maximum tree depth for base learners.\n",
      " |  learning_rate : float\n",
      " |      Boosting learning rate (xgb's \"eta\")\n",
      " |  n_estimators : int\n",
      " |      Number of boosted trees to fit.\n",
      " |  silent : boolean\n",
      " |      Whether to print messages while running boosting.\n",
      " |  objective : string or callable\n",
      " |      Specify the learning task and the corresponding learning objective or\n",
      " |      a custom objective function to be used (see note below).\n",
      " |  booster: string\n",
      " |      Specify which booster to use: gbtree, gblinear or dart.\n",
      " |  nthread : int\n",
      " |      Number of parallel threads used to run xgboost.  (Deprecated, please use n_jobs)\n",
      " |  n_jobs : int\n",
      " |      Number of parallel threads used to run xgboost.  (replaces nthread)\n",
      " |  gamma : float\n",
      " |      Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
      " |  min_child_weight : int\n",
      " |      Minimum sum of instance weight(hessian) needed in a child.\n",
      " |  max_delta_step : int\n",
      " |      Maximum delta step we allow each tree's weight estimation to be.\n",
      " |  subsample : float\n",
      " |      Subsample ratio of the training instance.\n",
      " |  colsample_bytree : float\n",
      " |      Subsample ratio of columns when constructing each tree.\n",
      " |  colsample_bylevel : float\n",
      " |      Subsample ratio of columns for each split, in each level.\n",
      " |  reg_alpha : float (xgb's alpha)\n",
      " |      L1 regularization term on weights\n",
      " |  reg_lambda : float (xgb's lambda)\n",
      " |      L2 regularization term on weights\n",
      " |  scale_pos_weight : float\n",
      " |      Balancing of positive and negative weights.\n",
      " |  base_score:\n",
      " |      The initial prediction score of all instances, global bias.\n",
      " |  seed : int\n",
      " |      Random number seed.  (Deprecated, please use random_state)\n",
      " |  random_state : int\n",
      " |      Random number seed.  (replaces seed)\n",
      " |  missing : float, optional\n",
      " |      Value in the data which needs to be present as a missing value. If\n",
      " |      None, defaults to np.nan.\n",
      " |  **kwargs : dict, optional\n",
      " |      Keyword arguments for XGBoost Booster object.  Full documentation of parameters can\n",
      " |      be found here: https://github.com/dmlc/xgboost/blob/master/doc/parameter.md.\n",
      " |      Attempting to set a parameter via the constructor args and **kwargs dict simultaneously\n",
      " |      will result in a TypeError.\n",
      " |      Note:\n",
      " |          **kwargs is unsupported by Sklearn.  We do not guarantee that parameters passed via\n",
      " |          this argument will interact properly with Sklearn.\n",
      " |  \n",
      " |  Note\n",
      " |  ----\n",
      " |  A custom objective function can be provided for the ``objective``\n",
      " |  parameter. In this case, it should have the signature\n",
      " |  ``objective(y_true, y_pred) -> grad, hess``:\n",
      " |  \n",
      " |  y_true: array_like of shape [n_samples]\n",
      " |      The target values\n",
      " |  y_pred: array_like of shape [n_samples]\n",
      " |      The predicted values\n",
      " |  \n",
      " |  grad: array_like of shape [n_samples]\n",
      " |      The value of the gradient for each sample point.\n",
      " |  hess: array_like of shape [n_samples]\n",
      " |      The value of the second derivative for each sample point\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      XGBClassifier\n",
      " |      XGBModel\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, max_depth=3, learning_rate=0.1, n_estimators=100, silent=True, objective='binary:logistic', booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, colsample_bytree=1, colsample_bylevel=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, random_state=0, seed=None, missing=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  evals_result(self)\n",
      " |      Return the evaluation results.\n",
      " |      \n",
      " |      If eval_set is passed to the `fit` function, you can call evals_result() to\n",
      " |      get evaluation results for all passed eval_sets. When eval_metric is also\n",
      " |      passed to the `fit` function, the evals_result will contain the eval_metrics\n",
      " |      passed to the `fit` function\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      evals_result : dictionary\n",
      " |      \n",
      " |      Example\n",
      " |      -------\n",
      " |      param_dist = {'objective':'binary:logistic', 'n_estimators':2}\n",
      " |      \n",
      " |      clf = xgb.XGBClassifier(**param_dist)\n",
      " |      \n",
      " |      clf.fit(X_train, y_train,\n",
      " |              eval_set=[(X_train, y_train), (X_test, y_test)],\n",
      " |              eval_metric='logloss',\n",
      " |              verbose=True)\n",
      " |      \n",
      " |      evals_result = clf.evals_result()\n",
      " |      \n",
      " |      The variable evals_result will contain:\n",
      " |      {'validation_0': {'logloss': ['0.604835', '0.531479']},\n",
      " |       'validation_1': {'logloss': ['0.41965', '0.17686']}}\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None, eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True, xgb_model=None)\n",
      " |      Fit gradient boosting classifier\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like\n",
      " |          Feature matrix\n",
      " |      y : array_like\n",
      " |          Labels\n",
      " |      sample_weight : array_like\n",
      " |          Weight for each instance\n",
      " |      eval_set : list, optional\n",
      " |          A list of (X, y) pairs to use as a validation set for\n",
      " |          early-stopping\n",
      " |      eval_metric : str, callable, optional\n",
      " |          If a str, should be a built-in evaluation metric to use. See\n",
      " |          doc/parameter.md. If callable, a custom evaluation metric. The call\n",
      " |          signature is func(y_predicted, y_true) where y_true will be a\n",
      " |          DMatrix object such that you may need to call the get_label\n",
      " |          method. It must return a str, value pair where the str is a name\n",
      " |          for the evaluation and value is the value of the evaluation\n",
      " |          function. This objective is always minimized.\n",
      " |      early_stopping_rounds : int, optional\n",
      " |          Activates early stopping. Validation error needs to decrease at\n",
      " |          least every <early_stopping_rounds> round(s) to continue training.\n",
      " |          Requires at least one item in evals.  If there's more than one,\n",
      " |          will use the last. Returns the model from the last iteration\n",
      " |          (not the best one). If early stopping occurs, the model will\n",
      " |          have three additional fields: bst.best_score, bst.best_iteration\n",
      " |          and bst.best_ntree_limit.\n",
      " |          (Use bst.best_ntree_limit to get the correct value if num_parallel_tree\n",
      " |          and/or num_class appears in the parameters)\n",
      " |      verbose : bool\n",
      " |          If `verbose` and an evaluation set is used, writes the evaluation\n",
      " |          metric measured on the validation set to stderr.\n",
      " |      xgb_model : str\n",
      " |          file name of stored xgb model or 'Booster' instance Xgb model to be\n",
      " |          loaded before training (allows training continuation).\n",
      " |  \n",
      " |  predict(self, data, output_margin=False, ntree_limit=0)\n",
      " |  \n",
      " |  predict_proba(self, data, output_margin=False, ntree_limit=0)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from XGBModel:\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  apply(self, X, ntree_limit=0)\n",
      " |      Return the predicted leaf every tree for each sample.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like, shape=[n_samples, n_features]\n",
      " |          Input features matrix.\n",
      " |      \n",
      " |      ntree_limit : int\n",
      " |          Limit number of trees in the prediction; defaults to 0 (use all trees).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array_like, shape=[n_samples, n_trees]\n",
      " |          For each datapoint x in X and for each tree, return the index of the\n",
      " |          leaf x ends up in. Leaves are numbered within\n",
      " |          ``[0; 2**(self.max_depth+1))``, possibly with gaps in the numbering.\n",
      " |  \n",
      " |  get_booster(self)\n",
      " |      Get the underlying xgboost Booster of this model.\n",
      " |      \n",
      " |      This will raise an exception when fit was not called\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      booster : a xgboost booster of underlying model\n",
      " |  \n",
      " |  get_params(self, deep=False)\n",
      " |      Get parameters.\n",
      " |  \n",
      " |  get_xgb_params(self)\n",
      " |      Get xgboost type parameters.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from XGBModel:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : array of shape = [n_features]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(XGBClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tried various parameters, this one is the best till now.\n",
    "parameters = [{'max_depth': [3], 'learning_rate': [0.1], 'n_estimators': [250], 'booster': ['gbtree', 'gblinear', 'dart']}]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86550000000000005"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy = grid_search.best_score_\n",
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'booster': 'gbtree',\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 3,\n",
       " 'n_estimators': 250}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters = grid_search.best_params_\n",
    "best_parameters"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "[Python] Artificial Neural Network.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
